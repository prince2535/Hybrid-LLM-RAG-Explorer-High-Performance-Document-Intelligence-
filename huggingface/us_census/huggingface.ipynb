{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T07:20:36.582183Z",
     "start_time": "2026-01-20T07:20:36.444546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Logic: 'Prompts' now live in 'langchain_core'\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Logic: 'Chains' live in 'langchain_classic' for version 1.2.6\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "\n",
    "print(\"‚úÖ Success: Everything is now properly imported!\")"
   ],
   "id": "a38a9cb5824a5a24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Success: Everything is now properly imported!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T08:04:41.849730Z",
     "start_time": "2026-01-20T08:04:37.844541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. Logic: Use \".\" to look in the CURRENT folder where the PDFs are\n",
    "# If your PDFs are in the same folder as this notebook, use \".\"\n",
    "path = \".\"\n",
    "\n",
    "print(f\"Checking for PDFs in: {os.path.abspath(path)}\")\n",
    "\n",
    "# 2. Logic: Load the documents\n",
    "loader = PyPDFDirectoryLoader(path)\n",
    "documents = loader.load()\n",
    "\n",
    "# 3. Logic: Safety Check\n",
    "if len(documents) == 0:\n",
    "    print(\"‚ùå Still 0 documents. Logic: Python is in the wrong folder.\")\n",
    "    print(f\"Files actually present here: {os.listdir(path)}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Loaded {len(documents)} pages.\")\n",
    "\n",
    "    # 4. Logic: Split the text\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    final_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "    print(f\"‚úÖ Created {len(final_documents)} chunks.\")\n",
    "\n",
    "    # 5. Logic: Show the first chunk safely\n",
    "    if len(final_documents) > 0:\n",
    "        print(\"\\n--- FIRST CHUNK DATA ---\")\n",
    "        print(final_documents[0].page_content[:200]) # Show first 200 chars"
   ],
   "id": "c2dbdf1a8074c369",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for PDFs in: D:\\Langchain\\huggingface\\us_census\n",
      "‚úÖ Loaded 63 pages.\n",
      "‚úÖ Created 316 chunks.\n",
      "\n",
      "--- FIRST CHUNK DATA ---\n",
      "Health Insurance Coverage Status and Type \n",
      "by Geography: 2021 and 2022\n",
      "American Community Survey Briefs\n",
      "ACSBR-015\n",
      "Issued September 2023\n",
      "Douglas Conway and Breauna Branch\n",
      "INTRODUCTION\n",
      "Demographic shift\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T08:04:41.856255Z",
     "start_time": "2026-01-20T08:04:41.851793Z"
    }
   },
   "cell_type": "code",
   "source": "len(final_documents)",
   "id": "161aba73c61ac297",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T08:06:05.264775Z",
     "start_time": "2026-01-20T08:05:32.974366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Embedding Using Huggingface\n",
    "huggingface_embeddings=HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",      #sentence-transformers/all-MiniLM-l6-v2\n",
    "    model_kwargs={'device':'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings':True}\n",
    "\n",
    ")"
   ],
   "id": "830a2fcea57e59aa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3388\\128432208.py:2: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  huggingface_embeddings=HuggingFaceBgeEmbeddings(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d1055a272b4447f81fb9a8e59b8d1d9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Langchain\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub\\models--BAAI--bge-small-en-v1.5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87a4acc54fc74d0793af627582ee4b90"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a2973df4ad04cddbe9a6177e4f871e0"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "860b3415bfdc47e6bc716656ce3f225c"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9eadb99439fa41f2bb2af41b17ab4084"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12feecbaf32447a98e3721c4bf652542"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78d2d80c7e1f451198748e40c9e7228e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d345ac59eb3d4accb65a295944c80b5f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "254f80886e7a42c9bf342088020730ef"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34286e5bec54440dbb48c591773be0d3"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90bf7073ae6a40e1b5fcc1ca6128f9a8"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T08:06:50.294421Z",
     "start_time": "2026-01-20T08:06:50.210851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import  numpy as np\n",
    "print(np.array(huggingface_embeddings.embed_query(final_documents[0].page_content)))\n",
    "print(np.array(huggingface_embeddings.embed_query(final_documents[0].page_content)).shape)"
   ],
   "id": "19d1adaf92016391",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07903485 -0.01134113 -0.02312097  0.02844461  0.05053344  0.05317826\n",
      " -0.01907787  0.03456026 -0.10211368 -0.02915702  0.0852426   0.05650727\n",
      " -0.02545439 -0.0330849  -0.00635735  0.04090864 -0.00628108  0.00356744\n",
      " -0.03854129  0.03667685 -0.04289803  0.03425252 -0.03116899 -0.03793729\n",
      "  0.01728391  0.01214924  0.00653119  0.01463565 -0.05529054 -0.15320712\n",
      "  0.00730845  0.03202944 -0.04701132 -0.01595974  0.0187445   0.02642936\n",
      " -0.02306378  0.08438035  0.04182485  0.05278177 -0.03057602  0.01564262\n",
      " -0.01689074  0.00529409 -0.02417436  0.00412995 -0.01889937 -0.00150625\n",
      " -0.00836945 -0.03390065  0.03515961 -0.00553131  0.04910938  0.05971856\n",
      "  0.05615963 -0.05105155  0.01475136 -0.01849959 -0.03284641  0.03576624\n",
      "  0.04947704 -0.00938883 -0.26202118  0.0975033   0.01715692  0.0478139\n",
      " -0.00556317 -0.00298307 -0.02207355 -0.04463669 -0.05760482  0.04815878\n",
      " -0.05522206  0.01635333  0.03299246  0.02147079  0.01296219  0.01462309\n",
      "  0.02174952 -0.00202999  0.02099538  0.03353847 -0.00345107 -0.04823537\n",
      "  0.05149956 -0.08948108  0.04491429 -0.03423372  0.02495744 -0.03332327\n",
      " -0.04124895  0.01226977  0.00551145  0.02813654  0.00750807  0.03364133\n",
      " -0.00718593 -0.00677302 -0.02375995  0.34350553 -0.02040539  0.00967846\n",
      " -0.0093651   0.01524741 -0.00692599 -0.0580374  -0.00443029  0.01115697\n",
      "  0.01746202  0.01258483  0.02158611 -0.02646193  0.01026773  0.04782214\n",
      " -0.03718098 -0.01986199  0.04008092  0.01574838  0.09363519 -0.02635872\n",
      " -0.01393858  0.03410932 -0.01630284 -0.04708786  0.02137171  0.06708884\n",
      "  0.05438907  0.15054181  0.0344439  -0.04218607  0.10422419 -0.04002277\n",
      " -0.00191296  0.00459117 -0.00292591  0.00371355 -0.02687687  0.03972115\n",
      " -0.00739632  0.05129854  0.00698695 -0.00043552 -0.00752807 -0.13413782\n",
      " -0.03140992  0.17964657 -0.02152573  0.04534229  0.02027219 -0.01826408\n",
      " -0.04439813  0.04787034 -0.03801551  0.04057755 -0.03817714  0.01659362\n",
      " -0.0036818   0.02469144 -0.02634713 -0.06727428  0.05705411 -0.03698837\n",
      " -0.05754095  0.01774044  0.04163105 -0.0269981  -0.01342312 -0.06434498\n",
      "  0.02320635  0.00476098  0.0134585   0.05142655  0.01828842 -0.02267212\n",
      "  0.08680936  0.02288989 -0.02278558 -0.00261808 -0.00936064 -0.0596436\n",
      "  0.0037007  -0.02772143 -0.05116594 -0.04951672 -0.01691759 -0.04342571\n",
      " -0.06551474  0.05782724  0.04989289 -0.01559615 -0.00385899  0.00827745\n",
      " -0.06377076  0.01969863 -0.01933413 -0.01095794 -0.059908   -0.02187357\n",
      "  0.03869356 -0.02963529 -0.03095985  0.0262945   0.00857688 -0.00225385\n",
      " -0.00917326  0.0200688   0.02308834 -0.06949829  0.03825644 -0.01321396\n",
      "  0.00288254  0.04065885  0.03197154  0.00364806  0.03610993  0.01653041\n",
      "  0.01282879 -0.02190454  0.02050887  0.03220994  0.03351384  0.06819049\n",
      "  0.09490158 -0.27463818 -0.0049903   0.00181547  0.0068773  -0.06947189\n",
      " -0.05266641 -0.04547604  0.02707842  0.00403481  0.08909722  0.06208605\n",
      " -0.00817409 -0.02176251  0.10530712  0.02105069 -0.08313887  0.0264829\n",
      " -0.02122216 -0.01542387 -0.00282385  0.00493171  0.0048772  -0.06012275\n",
      " -0.02174246  0.08150737 -0.01746733  0.06210523 -0.05241903 -0.07425196\n",
      "  0.00045816 -0.05536216  0.05762161 -0.00776098 -0.1196596   0.06155293\n",
      "  0.0177332  -0.07490137  0.00434345 -0.06374461 -0.03096171 -0.02682651\n",
      "  0.05158744 -0.06356605  0.02999    -0.01865463 -0.05194327  0.04636511\n",
      "  0.07127585 -0.08020446  0.01025251  0.00649389 -0.03402686 -0.03371226\n",
      " -0.01476089  0.02565074 -0.0625182  -0.03164579  0.03269229 -0.01906627\n",
      " -0.00269565  0.02393796  0.00502713  0.04807226 -0.00441301 -0.00810784\n",
      " -0.04506411  0.01010008 -0.0308529  -0.07091323  0.00998589  0.00276084\n",
      "  0.04710478 -0.02302788 -0.02459354  0.01797341 -0.02112836  0.04660883\n",
      " -0.00104203 -0.00374577 -0.04950179  0.04251799 -0.05733848  0.02055239\n",
      "  0.04219677 -0.01167059  0.01241851  0.01056793  0.00663803 -0.01598003\n",
      "  0.016328   -0.02056749 -0.01553832 -0.01156683 -0.01864408  0.00332142\n",
      "  0.00658677 -0.21910886  0.04714743  0.02075719 -0.02441516 -0.00868851\n",
      " -0.01634119 -0.02499121  0.00766706 -0.01083085 -0.02472531  0.05254847\n",
      "  0.08288425  0.11848132 -0.01936331 -0.00433765  0.00458103  0.06947738\n",
      "  0.0012453   0.02368699 -0.03457181  0.06163957 -0.06045358  0.14640087\n",
      " -0.03099669  0.01726847 -0.06827351 -0.0164134   0.0376527  -0.03385304\n",
      "  0.01721653  0.02592444 -0.00034787  0.02241217 -0.01919535  0.05005867\n",
      "  0.00834137  0.00977348  0.05592789  0.00274983  0.02592716 -0.04995015\n",
      " -0.02017875  0.02317918  0.01068105  0.064628   -0.02950335 -0.04529897\n",
      " -0.06358046 -0.01058145  0.06793744  0.00993985 -0.02914158  0.00441982\n",
      "  0.01224193 -0.05699342 -0.01181842 -0.06126492  0.03326268  0.00284463\n",
      " -0.01248828  0.02214624  0.04263505 -0.07597518  0.0123405   0.06002008]\n",
      "(384,)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T08:07:24.146885Z",
     "start_time": "2026-01-20T08:07:11.566644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## VectorStore Creation\n",
    "vectorstore=FAISS.from_documents(final_documents[:120],huggingface_embeddings)"
   ],
   "id": "e050ba8f4fc5a476",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T08:07:25.476058Z",
     "start_time": "2026-01-20T08:07:25.448862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Query using Similarity Search\n",
    "query=\"WHAT IS HEALTH INSURANCE COVERAGE?\"\n",
    "relevant_docments=vectorstore.similarity_search(query)\n",
    "\n",
    "print(relevant_docments[0].page_content)"
   ],
   "id": "b27a51eee3e4cf87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 U.S. Census Bureau\n",
      "WHAT IS HEALTH INSURANCE COVERAGE?\n",
      "This brief presents state-level estimates of health insurance coverage \n",
      "using data from the American Community Survey (ACS). The  \n",
      "U.S. Census Bureau conducts the ACS throughout the year; the \n",
      "survey asks respondents to report their coverage at the time of \n",
      "interview. The resulting measure of health insurance coverage, \n",
      "therefore, reflects an annual average of current comprehensive \n",
      "health insurance coverage status.* This uninsured rate measures a \n",
      "different concept than the measure based on the Current Population \n",
      "Survey Annual Social and Economic Supplement (CPS ASEC). \n",
      "For reporting purposes, the ACS broadly classifies health insurance \n",
      "coverage as private insurance or public insurance. The ACS defines \n",
      "private health insurance as a plan provided through an employer \n",
      "or a union, coverage purchased directly by an individual from an \n",
      "insurance company or through an exchange (such as healthcare.\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T08:07:44.939324Z",
     "start_time": "2026-01-20T08:07:44.927017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever=vectorstore.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":3})\n",
    "print(retriever)"
   ],
   "id": "fdbcf7bb87847d2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['FAISS', 'HuggingFaceBgeEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000187EE3A2A50> search_kwargs={'k': 3}\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T08:55:09.132801Z",
     "start_time": "2026-01-20T08:55:09.129310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=\"\""
   ],
   "id": "306d924db011cfa2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T08:45:25.755690Z",
     "start_time": "2026-01-20T08:45:18.942200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "load_dotenv()\n",
    "sec_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "# 1. Logic: Use a model that supports Text-Generation or specify the task\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\" # v0.2 is often more stable for text-generation\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    task=\"text-generation\", # Force the task type\n",
    "    huggingfacehub_api_token=sec_token,\n",
    "    temperature=0.7,\n",
    "    max_new_tokens=512,\n",
    ")\n",
    "\n",
    "# 2. Logic: Wrap it in ChatHuggingFace to fix the 'Conversational' error\n",
    "chat_model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "# 3. Test with a Message object\n",
    "query = [HumanMessage(content=\"What is health insurance coverage?\")]\n",
    "\n",
    "print(\"üöÄ Sending query to Hugging Face...\")\n",
    "\n",
    "try:\n",
    "    response = chat_model.invoke(query)\n",
    "    print(\"\\n--- LLM RESPONSE ---\")\n",
    "    print(response.content)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå API Error: {e}\")"
   ],
   "id": "bdc0cf74c419293f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Sending query to Hugging Face...\n",
      "\n",
      "--- LLM RESPONSE ---\n",
      " Health insurance is a type of insurance coverage that helps pay for medical and surgical expenses, as well as some related costs, such as deductibles, coinsurance, and copayments. It's designed to provide financial protection against the high cost of healthcare services. Health insurance can be provided through an employer, purchased individually, or obtained through government programs like Medicare or Medicaid. The specific coverage and benefits of health insurance plans can vary widely, so it's important to carefully review the details of any plan before enrolling. In general, health insurance can help protect individuals and families from financial hardship in the event of unexpected medical expenses.\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-01-20T08:47:05.726241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Hugging Face models can be run locally through the HuggingFacePipeline class.\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "hf = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"mistralai/Mistral-7B-v0.1\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\"temperature\": 0, \"max_new_tokens\": 300}\n",
    ")\n",
    "\n",
    "llm = hf\n",
    "llm.invoke(query)"
   ],
   "id": "b7cf656f7b9cb6dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2eb0b8c1d6448ab881169bcfafbe480"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Langchain\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub\\models--mistralai--Mistral-7B-v0.1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0722c59bffe4267a30dcd04fb2ce967"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc79e358b51b4f10909ea30bc419b175"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c546fc3cc2054a5aa759232299b1e8cc"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03d8eb2bae9a4b7dbf78453e85070b8c"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "568395be8f5b40deb1bd1838271720b9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8de7535aea06498cb9802893892d610d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2d51e67840a4951913c2fe5c917a349"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59d63e5a348d492cbe6e301916e995da"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T09:03:28.469993Z",
     "start_time": "2026-01-20T09:03:28.465473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Logic: In version 1.2.6, Prompts live in 'langchain_core'\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 2. Logic: Define your string\n",
    "prompt_template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "# 3. Logic: Create the object\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Success: PromptTemplate is defined using the modern Core path!\")"
   ],
   "id": "e8e9aa78c72510f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Success: PromptTemplate is defined using the modern Core path!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T09:06:04.492898Z",
     "start_time": "2026-01-20T09:06:04.488558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "prompt=PromptTemplate(template=prompt_template,input_variables=[\"context\",\"question\"])"
   ],
   "id": "a2881f270b394537",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T09:15:20.016723Z",
     "start_time": "2026-01-20T09:15:17.917989Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install langchain-huggingface\n",
   "id": "80dc8452bead6ca2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-huggingface in d:\\langchain\\venv\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in d:\\langchain\\venv\\lib\\site-packages (from langchain-huggingface) (0.36.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in d:\\langchain\\venv\\lib\\site-packages (from langchain-huggingface) (1.2.7)\n",
      "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in d:\\langchain\\venv\\lib\\site-packages (from langchain-huggingface) (0.22.1)\n",
      "Requirement already satisfied: filelock in d:\\langchain\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\langchain\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\langchain\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\langchain\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (6.0.3)\n",
      "Requirement already satisfied: requests in d:\\langchain\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\langchain\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\langchain\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.15.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\langchain\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\langchain\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\langchain\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.12.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\langchain\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in d:\\langchain\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\langchain\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\langchain\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\langchain\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\langchain\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\langchain\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.25.0)\n",
      "Requirement already satisfied: anyio in d:\\langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (4.12.0)\n",
      "Requirement already satisfied: certifi in d:\\langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\langchain\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\langchain\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\langchain\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\langchain\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\langchain\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\langchain\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.3.0)\n",
      "Requirement already satisfied: colorama in d:\\langchain\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (0.4.6)\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T09:15:50.967691Z",
     "start_time": "2026-01-20T09:15:50.932056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_classic.chains import RetrievalQA\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 1. Define Template\n",
    "template = \"\"\"\n",
    "Use the following pieces of context to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# 2. Initialize the Chain (Now 'hf' and 'retriever' are defined!)\n",
    "retrievalQA = RetrievalQA.from_chain_type(\n",
    "    llm=hf,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Success: RetrievalQA chain is ready!\")\n",
    "\n",
    "# 3. Run Query\n",
    "query = \"What is the main topic of these documents?\"\n",
    "response = retrievalQA.invoke({\"query\": query})\n",
    "\n",
    "print(\"\\n--- FINAL ANSWER ---\")\n",
    "print(response[\"result\"])"
   ],
   "id": "ea166f405eaecd51",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[31]\u001B[39m\u001B[32m, line 24\u001B[39m\n\u001B[32m     15\u001B[39m prompt = PromptTemplate(\n\u001B[32m     16\u001B[39m     template=template,\n\u001B[32m     17\u001B[39m     input_variables=[\u001B[33m\"\u001B[39m\u001B[33mcontext\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mquestion\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m     18\u001B[39m )\n\u001B[32m     20\u001B[39m \u001B[38;5;66;03m# 2. Initialize the Chain (Now 'hf' and 'retriever' are defined!)\u001B[39;00m\n\u001B[32m     21\u001B[39m retrievalQA = RetrievalQA.from_chain_type(\n\u001B[32m     22\u001B[39m     llm=hf,\n\u001B[32m     23\u001B[39m     chain_type=\u001B[33m\"\u001B[39m\u001B[33mstuff\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m     retriever=\u001B[43mretriever\u001B[49m,\n\u001B[32m     25\u001B[39m     return_source_documents=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m     26\u001B[39m     chain_type_kwargs={\u001B[33m\"\u001B[39m\u001B[33mprompt\u001B[39m\u001B[33m\"\u001B[39m: prompt}\n\u001B[32m     27\u001B[39m )\n\u001B[32m     29\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m‚úÖ Success: RetrievalQA chain is ready!\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     31\u001B[39m \u001B[38;5;66;03m# 3. Run Query\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'retriever' is not defined"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query=\"\"\"DIFFERENCES IN THE\n",
    "UNINSURED RATE BY STATE\n",
    "IN 2022\"\"\""
   ],
   "id": "4ddf7da2af0f3362"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Call the QA chain with our query.\n",
    "result = retrievalQA.invoke({\"query\": query})\n",
    "print(result['result'])"
   ],
   "id": "2fd388b2238fcf9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "76c76447ee430845"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5aeaf07ec113c448"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
