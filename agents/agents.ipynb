{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-01-19T06:48:22.487721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_classic.agents import create_openai_tools_agent\n",
    "!pip install arxiv\n"
   ],
   "id": "5b3f7e7e06d751fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T06:48:24.434087600Z",
     "start_time": "2026-01-19T06:12:43.902649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n"
   ],
   "id": "f80b37ff89d94a42",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T06:48:24.434087600Z",
     "start_time": "2026-01-19T06:12:43.932464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n"
   ],
   "id": "a0efe933c82d3bb4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T06:48:24.434087600Z",
     "start_time": "2026-01-19T06:12:43.948853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper)"
   ],
   "id": "af8d9b30d5e90a3b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T06:48:24.439601800Z",
     "start_time": "2026-01-19T06:12:43.967711Z"
    }
   },
   "cell_type": "code",
   "source": "wiki.name\n",
   "id": "b247bfe3207fb259",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T06:48:24.440606800Z",
     "start_time": "2026-01-19T06:12:43.985867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import requests\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 1. SETUP\n",
    "DB_PATH = \"faiss_index_web\"\n",
    "\n",
    "# 2. LOGIC: Initialize Models (Using llama3.2 is safer for CUDA errors)\n",
    "# If llama3 continues to crash, change \"llama3\" to \"llama3.2\" below.\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "\n",
    "# 3. LOGIC: Load Database\n",
    "if os.path.exists(DB_PATH):\n",
    "    vectordb = FAISS.load_local(DB_PATH, embeddings, allow_dangerous_deserialization=True)\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "    print(\"✅ Database loaded successfully.\")\n",
    "else:\n",
    "    print(\"❌ Error: Run your scraping code first to create the index!\")\n",
    "\n",
    "# 4. LOGIC: Build the Chain\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "format_docs = lambda docs: \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"input\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 5. EXECUTION with Error Handling\n",
    "print(\"\\n--- SYSTEM READY ---\")\n",
    "try:\n",
    "    print(\"AI EXPLANATION:\")\n",
    "    print(rag_chain.invoke(\"What is LangSmith?\"))\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ GPU Error detected. Try running 'ollama pull llama3.2' and changing the model name in the code.\")\n",
    "    print(f\"Detailed Error: {e}\")"
   ],
   "id": "47a52c718e7dacc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Database loaded successfully.\n",
      "\n",
      "--- SYSTEM READY ---\n",
      "AI EXPLANATION:\n",
      "LangSmith is a tool for developing, debugging, and deploying Large Language Model (LLM) applications. It provides a framework-agnostic platform that allows users to prototype locally, deploy to production with integrated monitoring and evaluation, and build more reliable AI systems.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T06:48:24.441655400Z",
     "start_time": "2026-01-19T06:12:55.406388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Logic: Import from 'langchain_core' because it's already in your memory\n",
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "\n",
    "# 2. Logic: Create the Tool\n",
    "# This connects your PDF 'retriever' to a tool an Agent can use\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    'langsmith_search',\n",
    "    \"Use this tool to search for technical details in the 'Attention Is All You Need' PDF.\"\n",
    ")\n",
    "\n",
    "print(\"✅ Success: Tool is created and ready!\")"
   ],
   "id": "ba1d24be4c9d5473",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success: Tool is created and ready!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T06:48:24.446600900Z",
     "start_time": "2026-01-19T06:12:55.423832Z"
    }
   },
   "cell_type": "code",
   "source": "retriever_tool.name",
   "id": "6175629c51e1971b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T06:48:24.447602Z",
     "start_time": "2026-01-19T06:12:55.437564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import arxiv\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "# Create the specific tool\n",
    "arxiv_tool = ArxivQueryRun(api_wrapper=ArxivAPIWrapper(top_k_results=1))\n",
    "\n",
    "# ✅ Logic: Use the variable YOU created, not the library name\n",
    "print(arxiv_tool.name)"
   ],
   "id": "c91e16c798622e28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T06:48:24.447602Z",
     "start_time": "2026-01-19T06:12:55.495659Z"
    }
   },
   "cell_type": "code",
   "source": "tools=[wiki,arxiv,retriever_tool]\n",
   "id": "703666d9efcedbd0",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T06:48:24.450601100Z",
     "start_time": "2026-01-19T06:12:55.506721Z"
    }
   },
   "cell_type": "code",
   "source": "tools",
   "id": "7e28f6c04fbd4b72",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'D:\\\\Langchain\\\\venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " <module 'arxiv' from 'D:\\\\Langchain\\\\venv\\\\Lib\\\\site-packages\\\\arxiv\\\\__init__.py'>,\n",
       " StructuredTool(name='langsmith_search', description=\"Use this tool to search for technical details in the 'Attention Is All You Need' PDF.\", args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=<function create_retriever_tool.<locals>.func at 0x000002BCC2C1D940>, coroutine=<function create_retriever_tool.<locals>.afunc at 0x000002BCC2C1DBC0>)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T06:48:24.451603400Z",
     "start_time": "2026-01-19T06:12:55.518918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Logic: Use the dedicated Ollama package (Standard for 2026)\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# 2. Logic: Future-Proofing\n",
    "# No API Keys needed! Safe from leaks and charges.\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3\",\n",
    "    temperature=0,\n",
    "    # This ensures the model stays consistent\n",
    ")\n",
    "\n",
    "print(\"✅ Success: Local LLM initialized. No OpenAI Key required.\")"
   ],
   "id": "26f475ffde3c8619",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success: Local LLM initialized. No OpenAI Key required.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T06:48:37.983456Z",
     "start_time": "2026-01-19T06:48:34.053402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import langchainhub as hub\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "# ✅ Logic: These are the correct paths for LangChain 1.x\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.react.agent import create_react_agent\n",
    "\n",
    "# 1. Initialize Models\n",
    "llm = ChatOllama(model=\"llama3\", temperature=0)\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "# 2. Load Memory\n",
    "if os.path.exists(\"faiss_index\"):\n",
    "    db = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "    retriever = db.as_retriever()\n",
    "else:\n",
    "    print(\"❌ ERROR: Run your DB saving code first!\")\n",
    "\n",
    "# 3. Define the Tool\n",
    "def search_pdf(query: str):\n",
    "    docs = retriever.invoke(query)\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "retriever_tool = Tool(\n",
    "    name=\"search_pdf_tool\",\n",
    "    func=search_pdf,\n",
    "    description=\"Use this for technical questions about the Attention paper.\"\n",
    ")\n",
    "tools = [retriever_tool]\n",
    "\n",
    "# 4. Pull Prompt & Create Agent\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# 5. Build the Executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# 6. Run it\n",
    "print(\"\\n--- AGENT STARTING ---\")\n",
    "query = \"What is the formula for Scaled Dot-Product Attention?\"\n",
    "# Logic: Always use a dictionary for Agents\n",
    "response = agent_executor.invoke({\"input\": query})\n",
    "\n",
    "print(\"\\n--- FINAL ANSWER ---\")\n",
    "print(response[\"output\"])"
   ],
   "id": "65f749a5e3f8d707",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AgentExecutor' from 'langchain.agents' (D:\\Langchain\\venv\\Lib\\site-packages\\langchain\\agents\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtools\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Tool\n\u001B[32m      7\u001B[39m \u001B[38;5;66;03m# ✅ Logic: These are the correct paths for LangChain 1.x\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01magents\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AgentExecutor\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01magents\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mreact\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01magent\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m create_react_agent\n\u001B[32m     11\u001B[39m \u001B[38;5;66;03m# 1. Initialize Models\u001B[39;00m\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'AgentExecutor' from 'langchain.agents' (D:\\Langchain\\venv\\Lib\\site-packages\\langchain\\agents\\__init__.py)"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c22f4034ffba45b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cc43ba3f2647b277"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2cf326f3c695e3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cd13e12247735446"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
